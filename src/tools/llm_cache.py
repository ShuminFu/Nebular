"""ç”¨äºŽæµ‹è¯•LLMç”Ÿæˆçš„ç¼“å­˜æœºåˆ¶ã€‚
åŸºäºŽURLç¼“å­˜æ”¹é€ ï¼Œæ”¯æŒå¯¹LLMè¯·æ±‚å“åº”çš„ç¼“å­˜ï¼Œé¿å…é‡å¤è°ƒç”¨APIã€‚
"""


import logging
import json
import os
from datetime import datetime, timedelta
import hashlib

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class LLMCache:
    """ä¸“é—¨ç”¨äºŽç¼“å­˜LLMå“åº”çš„ç¼“å­˜ç±»"""

    def __init__(self, ttl_seconds=3600, cache_dir=None):
        self.ttl_seconds = ttl_seconds
        # è®¾ç½®ç¼“å­˜ç›®å½•ï¼Œé»˜è®¤åœ¨å½“å‰æ–‡ä»¶ç›®å½•ä¸‹çš„ .llm_cache
        current_file_dir = os.path.dirname(os.path.abspath(__file__))
        self.cache_dir = cache_dir or os.path.join(current_file_dir, '.llm_cache')
        # ç¡®ä¿ç¼“å­˜ç›®å½•å­˜åœ¨
        os.makedirs(self.cache_dir, exist_ok=True)
        logger.info(f"ä½¿ç”¨LLMç¼“å­˜ç›®å½•: {self.cache_dir}")

    def _generate_cache_key(self, model: str, messages: list, **kwargs) -> str:
        """ç”Ÿæˆç¼“å­˜é”®

        è€ƒè™‘æ‰€æœ‰å¯èƒ½å½±å“LLMè¾“å‡ºçš„å‚æ•°ï¼ŒåŒ…æ‹¬ï¼š
        - æ¨¡åž‹åç§°
        - æ¶ˆæ¯å†…å®¹
        - å…¶ä»–å‚æ•°(temperature, top_pç­‰)
        """
        # åˆ›å»ºä¸€ä¸ªåŒ…å«æ‰€æœ‰å‚æ•°çš„å­—å…¸
        cache_dict = {
            'model': model,
            'messages': messages,
            **kwargs
        }
        # å°†å­—å…¸è½¬æ¢ä¸ºè§„èŒƒåŒ–çš„JSONå­—ç¬¦ä¸²
        cache_str = json.dumps(cache_dict, sort_keys=True)
        # ä½¿ç”¨MD5ç”Ÿæˆç¼“å­˜é”®
        return hashlib.md5(cache_str.encode()).hexdigest()

    def _get_cache_path(self, cache_key: str) -> str:
        """èŽ·å–ç¼“å­˜æ–‡ä»¶è·¯å¾„"""
        return os.path.join(self.cache_dir, f"{cache_key}.json")

    def get(self, model: str, messages: list, **kwargs) -> dict:
        """èŽ·å–ç¼“å­˜çš„LLMå“åº”

        Args:
            model: æ¨¡åž‹åç§°
            messages: æ¶ˆæ¯åˆ—è¡¨
            **kwargs: å…¶ä»–å‚æ•°(temperature, top_pç­‰)

        Returns:
            dict: ç¼“å­˜çš„å“åº”æ•°æ®ï¼Œå¦‚æžœæ²¡æœ‰ç¼“å­˜åˆ™è¿”å›žNone
        """
        cache_key = self._generate_cache_key(model, messages, **kwargs)
        cache_path = self._get_cache_path(cache_key)

        if os.path.exists(cache_path):
            try:
                with open(cache_path, 'r', encoding='utf-8') as f:
                    cached_data = json.load(f)
                    # æ£€æŸ¥æ˜¯å¦è¿‡æœŸ
                    if datetime.fromisoformat(cached_data['expires']) > datetime.now():
                        logger.info(f"ðŸŽ¯ å‘½ä¸­LLMç¼“å­˜: {model}")
                        return cached_data['data']
                    else:
                        logger.info(f"âŒ› LLMç¼“å­˜è¿‡æœŸ: {model}")
                        os.remove(cache_path)
            except (json.JSONDecodeError, KeyError, OSError) as e:
                logger.warning(f"è¯»å–LLMç¼“å­˜å¤±è´¥: {e}")
                if os.path.exists(cache_path):
                    os.remove(cache_path)
        return None

    def set(self, model: str, messages: list, response_data: dict, **kwargs):
        """è®¾ç½®LLMå“åº”ç¼“å­˜

        Args:
            model: æ¨¡åž‹åç§°
            messages: æ¶ˆæ¯åˆ—è¡¨
            response_data: å“åº”æ•°æ®
            **kwargs: å…¶ä»–å‚æ•°(temperature, top_pç­‰)
        """
        cache_key = self._generate_cache_key(model, messages, **kwargs)
        cache_path = self._get_cache_path(cache_key)

        cache_data = {
            'data': response_data,
            'expires': (datetime.now() + timedelta(seconds=self.ttl_seconds)).isoformat()
        }

        try:
            with open(cache_path, 'w', encoding='utf-8') as f:
                json.dump(cache_data, f, ensure_ascii=False, indent=2)
            logger.info(f"ðŸ’¾ å·²ç¼“å­˜LLMå“åº”: {model} -> {cache_path}")
        except OSError as e:
            logger.error(f"å†™å…¥LLMç¼“å­˜å¤±è´¥: {e}")

    def clear(self):
        """æ¸…é™¤æ‰€æœ‰LLMç¼“å­˜"""
        for file in os.listdir(self.cache_dir):
            if file.endswith('.json'):
                os.remove(os.path.join(self.cache_dir, file))
        logger.info("ðŸ§¹ å·²æ¸…é™¤æ‰€æœ‰LLMç¼“å­˜")
